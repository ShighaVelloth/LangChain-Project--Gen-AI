#  Eyes of AI: Empowering the Visually Impaired with Smarter Image Analysis

This project is an **AI-powered assistant** designed to help visually impaired individuals understand their surroundings through images. The app offers the following functionalities:  

- **üéØ Object and Scene Recognition**  
- **üîç Text Detection (OCR) and Conversion**  
- **üîä Text-to-Speech (TTS) for Audio Descriptions**  
- **‚ö†Ô∏è Hazard Detection and Safety Alerts**  

---

## **Features**  

- **Image-to-Text and Audio Conversion**  
  Extracts text from uploaded images and converts it into **audio** for seamless accessibility.  

- **Contextual Scene Understanding**  
  Provides descriptive summaries of **objects**, **text**, and **symbols** within the image for better comprehension.  

- **Hazard Detection**  
  Identifies potential **risks** or **obstacles** in the image and provides **safety alerts** to assist with navigation.  

- **User-Friendly Interface**  
  A simple and intuitive UI optimized for visually impaired users with **single-click operations** and organized tabs for easy navigation.  

---

## **Technologies Used**  

- **Python**: Programming language used for development.  
- **Streamlit**: Framework for building interactive web applications with accessibility-focused UI.  
- **BLIP (Bootstrapped Language-Image Pretraining)**: Advanced image captioning model for context-aware scene descriptions.  
- **YOLO (You Only Look Once)**: Object detection model for identifying objects and obstacles in uploaded images.  
- **EasyOCR**: Optical Character Recognition (OCR) tool for extracting text from images.  
- **LangChain**: Framework for integrating LLMs (like Google Generative AI).  
- **Google Generative AI (Gemini)**: For generating detailed and context-aware scene descriptions.  
- **gTTS (Google Text-to-Speech)**: Converts the detected text into speech for audio output.  

---

