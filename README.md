# ğŸŒŸ  Eyes of AI: Empowering the Visually Impaired with Smarter Image Analysis

This project is an **AI-powered assistant** designed to help visually impaired individuals understand their surroundings through images. The app offers the following functionalities:  

- **ğŸ¯ Object and Scene Recognition**  
- **ğŸ” Text Detection (OCR) and Conversion**  
- **ğŸ”Š Text-to-Speech (TTS) for Audio Descriptions**  
- **âš ï¸ Hazard Detection and Safety Alerts**  

---

## ** Features**  

- **ğŸ–¼ï¸ Image-to-Text and Audio Conversion**  
  Extracts text from uploaded images and converts it into **audio** for seamless accessibility.  

- **ğŸ•µï¸ Contextual Scene Understanding**  
  Provides descriptive summaries of **objects**, **text**, and **symbols** within the image for better comprehension.  

- **âš ï¸ Hazard Detection**  
  Identifies potential **risks** or **obstacles** in the image and provides **safety alerts** to assist with navigation.  

- **ğŸ–±ï¸ User-Friendly Interface**  
  A simple and intuitive UI optimized for visually impaired users with **single-click operations** and organized tabs for easy navigation.  

---

## **ğŸ› ï¸ Technologies Used**  

- ** Python**: Programming language used for development.  
- ** Streamlit**: Framework for building interactive web applications with accessibility-focused UI.  
- ** BLIP (Bootstrapped Language-Image Pretraining)**: Advanced image captioning model for context-aware scene descriptions.  
- ** YOLO (You Only Look Once)**: Object detection model for identifying objects and obstacles in uploaded images.  
- ** EasyOCR**: Optical Character Recognition (OCR) tool for extracting text from images.  
- ** LangChain**: Framework for integrating LLMs (like Google Generative AI).  
- ** Google Generative AI (Gemini)**: For generating detailed and context-aware scene descriptions.  
- ** gTTS (Google Text-to-Speech)**: Converts the detected text into speech for audio output.  

---

